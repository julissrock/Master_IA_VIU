{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DCGAN_FashionMNIST_Práctica.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eyrjJP7MqpAN"},"source":["En este ejemplo vamos a tratar de generar imágenes similares a las del dataset de ropa FashionMNIST.\n","\n","Pero esta vez lo váis a hacer vosotros :)"]},{"cell_type":"code","metadata":{"id":"8bCnkVIwrJz8","executionInfo":{"status":"ok","timestamp":1634839614661,"user_tz":-120,"elapsed":2949,"user":{"displayName":"Félix José Fuentes Hurtado","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08557990006797564533"}}},"source":["# importamos las librerías necesarias\n","import numpy as np\n","# buscad el dataset Fashion MNIST disponible en Keras e importadlo\n","# https://keras.io/datasets/\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"7y3jZ4gVrMAz"},"source":["# definimos el discriminador: en este caso va a ser convolucional\n","def define_discriminator(in_shape=(28,28,1)):\n","    model = Sequential()\n","    model.add(Conv2D(128, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dropout(0.4))\n","    model.add(Conv2D(128, (3,3), strides=(2, 2), padding='same'))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dropout(0.4))\n","    model.add(Flatten())\n","    model.add(Dense(1, activation='sigmoid'))\n","    # AQUÍ VUESTRO CÓDIGO\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nucb657PrT_R"},"source":["# definimos el generador\n","def define_generator(latent_dim):\n","    model = Sequential()\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0CKU8au2sfY9"},"source":["# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n","def define_gan(g_model, d_model):\n","    # Recordad: congeláis el discriminador\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","\n","    # creáis el modelo y conectáis el G(z) al D(x)\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","\n","    # añadimos el generador primero: él es el encargado de generar una muestra\n","    # a partir del espacio latente\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","    \n","    # y el discriminador después: le introducimos la muestra generada por el \n","    # G(z) para que nos diga si cree que es real o fake\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","    \n","    # y compiláis el modelo\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"acd2xBRrs1Sm"},"source":["# definimos las funciones para cargar el MNIST\n","def load_real_samples():\n","    # load mnist dataset\n","    (trainX, _), (_, _) = load_data()\n","    # expand to 3d, e.g. add channels dimension\n","    X = np.expand_dims(trainX, axis=-1)\n","    # convert from unsigned ints to floats\n","    X = X.astype('float32')\n","    # scale from [0,255] to [0,1]\n","    X = X / 255.0\n","    return X\n","\n","# nos creamos una función que nos devuelva n_samples del dataset con sus \n","# etiquetas (1) \n","def generate_real_samples(dataset, n_samples):\n","    # seleccionamos n_samples muestras aleatoriamente\n","    ix = np.random.randint(0, dataset.shape[0], n_samples)\n","    # las cogemos\n","    X = dataset[ix]\n","    # generamos las etiquetas reales (1)\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","\n","\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0o9oAmXgs61c"},"source":["# generamos los vectores latentes que introduciremos al generador\n","def generate_latent_points(latent_dim, batch_size):\n","    # generamos un vector de batch_size * latent_dim números aleatorios\n","    # latent_dim es la dimensión del vector latente\n","    # batch_size es el número de elementos por batch\n","    \n","    # AQUÍ VUESTRO CÓDIGO\n","\n","    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n","    x_input = x_input.reshape(batch_size, latent_dim)\n","    return x_input\n","\n","# creamos datos fake con el generador (dinero falsificado)\n","def generate_fake_samples(g_model, latent_dim, n_samples): \n","    # usamos la función anterior para generar los vectores latentes que \n","    # necesitamos para generar muestras fake\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    # le introducimos los vectores latentes al generador para obtener\n","    # muestras similares a las reales\n","    X = g_model.predict(x_input)\n","    # le asignamos la etiqueta 0 (porque utilizaremos esta función para\n","    # entrenar el D)\n","\n","    # AQUÍ VUESTRO CÓDIGO\n","\n","    return X, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihC0sltV2URE"},"source":["# función para guardar las imágenes generadas\n","def save_plot(examples, epoch, n=10):\n","    for i in range(n * n):\n","        plt.subplot(n, n, 1 + i)\n","        plt.axis('off')\n","        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n","    # guardamos las imágenes\n","    filename = 'generated_plot_e%03d.png' % (epoch+1)\n","    plt.savefig(filename)\n","    plt.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vBkSW8WH2Zzz"},"source":["# función para entrenar la GAN: el discriminador y el generador\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    # bucle para las epochs\n","    for epoch in range(n_epochs):\n","        # bucle para los batch\n","        for batch in range(bat_per_epo):\n","            # preparamos los datos reales\n","            \n","            # AQUÍ VUESTRO CÓDIGO\n","\n","            # generamos 'half_batch' datos falsos\n","            \n","            # AQUÍ VUESTRO CÓDIGO\n","\n","            # juntamos las imágenes/etiquetas reales con las falsas\n","            X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n","            # actualizamos los pesos del discriminador\n","            \n","            # AQUÍ VUESTRO CÓDIGO\n","            \n","            # preparamos los puntos en el espacio latente: serán la entrada al\n","            # modelo GAN con el que entrenaremos el generador\n","            \n","            # AQUÍ VUESTRO CÓDIGO\n","            \n","            # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n","            # para que piense que las muestras que le introducimos son reales, y\n","            # en caso de que diga que no son reales, aprovechamos la información\n","            # de sus gradientes para actualizar el G(z) para que la próxima vez\n","            # los datos generados por G(z) sean más plausibles (parecidos a los \n","            # reales)\n","            \n","            # AQUÍ VUESTRO CÓDIGO\n","            \n","            # como acabamos de ver, entrenamos el generador de forma que actualice\n","            # sus pesos usando los gradientes del discriminador\n","            # tened en cuenta que en este modelo (gan_model) el discriminador está\n","            # congelado, por lo que no se actualizan sus pesos: no queremos \"untar\"\n","            # a nuestro policía, lo que queremos es fabricar dinero más realista.\n","            \n","            # AQUÍ VUESTRO CÓDIGO\n","            \n","            # mostramos el progreso\n","            print('>%d, %d/%d, d=%.3f, g=%.3f' % (epoch+1, batch+1, bat_per_epo, d_loss, g_loss))\n","        # evaluate the model performance, sometimes\n","        if (epoch+1) % 10 == 0 or epoch == 0:\n","            # preparamos ejemplos reales\n","            X_real, y_real = generate_real_samples(dataset, n_batch)\n","            # evaluamos el discriminador con datos reales\n","            _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","            # preparamos ejemplos fake\n","            x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n","            # evaluamos el discriminador con datos fake\n","            _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","            # mostramos cómo de bueno es nuestro policía\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","            # guardamos las imágenes generadas\n","            save_plot(x_fake, epoch)\n","            # guardamos el generador para tenerlo disponible más tarde\n","            filename = 'generator_model_%03d.h5' % (epoch + 1)\n","            g_model.save(filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkIcUyas2Zz2"},"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# load image data\n","dataset = load_real_samples()\n","# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9LXaAVb4Rri"},"source":["ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSzI2O-LCmc_"},"source":["plt.imshow(plt.imread('generated_plot_e001.png'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Ez8QfGI4UjH"},"source":["plt.imshow(plt.imread('generated_plot_e010.png'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dixkDKlF4pXX"},"source":["plt.imshow(plt.imread('generated_plot_e100.png'))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vHJ_OoiWBlyt"},"source":["Nada mal, ¿verdad? Pero... ¿y si quisiéramos generar solo zapatos? ¿O solo camisetas?\n","\n","Para ello, necesitamos transformar esta GAN en una GAN condicional o CGAN.\n","\n","Podéis guiaros con este ejemplo: https://keras.io/examples/generative/conditional_gan/."]},{"cell_type":"code","metadata":{"id":"cCstSMyJCDeD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NcWltItdCDbZ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9JcBMJlhCDYp"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSodWhQyCDWQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5YvqnEZpCDHq"},"source":[""],"execution_count":null,"outputs":[]}]}