{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"t1iE9XTGLU2V"},"source":["# V11 - Otros usos de aprendizaje no-supervisado\n"]},{"cell_type":"markdown","metadata":{"id":"jbWgfBEtNbgS"},"source":["El notebook de esta clase va a ser un poco diferente de los anteriores. En este caso vamos a ver dos ejemplos independientes de aprendizaje no-supervisado que no ha dado tiempo a ver en clase. El primero va a ser el uso de grafos para segmentación, y el segundo, el uso de modelos generativos adversarios para generación de contenido."]},{"cell_type":"markdown","metadata":{"id":"bbJ-dH7eL4Nf"},"source":["## Segmentación mediante grafos\n","\n","Este algoritmo construye primero un grafo de adyacencia de regiones y luego realiza el corte mínimo normalizado. En fuentes podéis conocer más sobre cómo funciona el agoritmo.\n","\n","Vamos a ver un ejemplo:"]},{"cell_type":"code","metadata":{"id":"-Cy4uu0RMPi3"},"source":["!pip install scikit-image==0.16.2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m1hgbYsbLufl"},"source":["### Corte normalizado"]},{"cell_type":"code","metadata":{"id":"-7rnRbR1Lx7z"},"source":["from skimage import data, segmentation, color\n","from skimage.future import graph\n","from matplotlib import pyplot as plt\n","\n","\n","img = data.coffee()\n","plt.imshow(img)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels1 = ## Tu código aqui ##\n","out1 = color.label2rgb(labels1, img, kind='avg')\n","\n","g = graph.rag_mean_color(img, labels1, mode='similarity')\n","labels2 = graph.cut_normalized(labels1, g)\n","out2 = color.label2rgb(labels2, img, kind='avg')\n","\n","fig, ax = plt.subplots(nrows=2, sharex=True, sharey=True, figsize=(6, 8))\n","\n","ax[0].imshow(out1)\n","ax[1].imshow(out2)"],"metadata":{"id":"KmCfTlRg7khM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VyXMK2A_Io83"},"source":["### GrabCut:\n","\n","En este ejemplo vamos a ver cómo podemos usar el corte mínimo de un grafo para segmentar background de foreground en una imagen.\n","\n","Pongamos como ejemplo esta imagen:\n","\n","<img src=\"https://opencv24-python-tutorials.readthedocs.io/en/latest/_images/grabcut_output1.jpg\">\n","\n","Como podéis ver, disponemos de una bounding box y de semillas para background y para foreground.\n","\n","Lo que hace el algoritmo de GrabCut es construir un grafo asignando todos los pixels o bien a una fuente a un sumidero, y después encuentra el mínimo corte en dicho grafo:\n","\n","<img src=\"https://opencv24-python-tutorials.readthedocs.io/en/latest/_images/grabcut.jpg\">\n","\n","Tenemos la suerte de que este algoritmo se encuentra implementado en OpenCV: `cv2.grabCut()`. Veamos sus argumentos.\n","\n","`img` - Input image\n","\n","`mask` - It is a mask image where we specify which areas are background, foreground or probable background/foreground etc. It is done by the following flags, cv2.GC_BGD, cv2.GC_FGD, cv2.GC_PR_BGD, cv2.GC_PR_FGD, or simply pass 0,1,2,3 to image.\n","\n","`rect` - It is the coordinates of a rectangle which includes the foreground object in the format (x,y,w,h)\n","\n","`bdgModel, fgdModel` - These are arrays used by the algorithm internally. You just create two np.float64 type zero arrays of size (1,65).\n","\n","`iterCount` - Number of iterations the algorithm should run.\n","\n","`mode` - It should be cv2.GC_INIT_WITH_RECT or cv2.GC_INIT_WITH_MASK or combined which decides whether we are drawing rectangle or final touchup strokes.\n","\n","First let’s see with rectangular mode. We load the image, create a similar mask image. We create fgdModel and bgdModel. We give the rectangle parameters. It’s all straight-forward. Let the algorithm run for 5 iterations. Mode should be cv2.GC_INIT_WITH_RECT since we are using rectangle. Then run the grabcut. It modifies the mask image. In the new mask image, pixels will be marked with four flags denoting background/foreground as specified above. So we modify the mask such that all 0-pixels and 2-pixels are put to 0 (ie background) and all 1-pixels and 3-pixels are put to 1(ie foreground pixels). Now our final mask is ready. Just multiply it with input image to get the segmented image."]},{"cell_type":"code","metadata":{"id":"41qS0hpwJ_3y"},"source":["!wget https://raw.githubusercontent.com/abidrahmank/OpenCV2-Python-Tutorials/master/data/messi5.jpg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lHa_3ZCWJz5x"},"source":["import numpy as np\n","import cv2\n","from matplotlib import pyplot as plt\n","plt.rcParams['figure.figsize'] = [8, 8]\n","\n","img_orig = cv2.imread('messi5.jpg')\n","mask = np.zeros(img_orig.shape[:2],np.uint8)\n","\n","bgdModel = np.zeros((1,65),np.float64)\n","fgdModel = np.zeros((1,65),np.float64)\n","\n","rect = (50,50,450,290)\n","cv2.grabCut(img_orig, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n","\n","mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n","img = img_orig*mask2[:,:,np.newaxis]\n","\n","plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-d9-SRiHKZ8t"},"source":["Fijaos que el pelo y el cesped entre las piernas no se ha segmentado bien. ¿Cómo podemos arreglarlo?"]},{"cell_type":"code","metadata":{"id":"51qvMIyMN9IG"},"source":["!wget -O newmask.png https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ6doDpZUR3q0TeUQyjBUc_dB-N6xBfCnNOp4SbxDumtKDB_1TG&s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2J-Qee0PJcL"},"source":["# newmask is the mask image I manually labelled\n","newmask = cv2.imread('newmask.png',0)\n","newmask = cv2.resize(newmask, img.shape[:2][::-1])\n","plt.imshow(img_orig), plt.imshow(newmask, alpha=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n8fQV8ipMGxC"},"source":["# whereever it is marked white (sure foreground), change mask=1\n","# whereever it is marked black (sure background), change mask=0\n","mask[newmask == 0] = 0\n","mask[newmask == 255] = 1\n","\n","mask, bgdModel, fgdModel = ## Tu código aqui ##\n","\n","mask = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n","img = img_orig*mask[:,:,np.newaxis]\n","plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xGhfage_OqX4"},"source":["Y afinando más la máscara, podríamos llegar a obtener perfectamente a Messi sin nada de fondo."]},{"cell_type":"markdown","metadata":{"id":"L8PanOpRIvt6"},"source":["### Fuentes:\n","\n","- https://scikit-image.org/docs/0.16.x/auto_examples/segmentation/plot_ncut.html?highlight=normalized%20cut\n","- https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_grabcut/py_grabcut.html\n","\n","### Recursos interesantes:\n","\n","- https://medium.com/stellargraph/knowing-your-neighbours-machine-learning-on-graphs-9b7c3d0d5896"]},{"cell_type":"code","metadata":{"id":"CZxHcHMDM-_s"},"source":["# Enlaces para el algoritmo PageRank\n","# https://medium.com/analytics-vidhya/how-google-search-works-page-rank-algorithm-using-python-9643d9c9a981\n","# https://medium.com/@arpanspeaks/custom-pagerank-implementation-in-python-and-verification-in-ms-excel-9ab6c690aaf5\n","## Enlace para algoritmo de asociación ##\n","# https://intellipaat.com/blog/data-science-apriori-algorithm/\n","# https://pbpython.com/market-basket-analysis.html\n","# https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n","# https://medium.com/swlh/a-tutorial-about-market-basket-analysis-in-python-predictive-hacks-497dc6e06b27"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"satXOenuP5-F"},"source":["### Fuentes\n","\n","- https://github.com/Madhu009/Deep-math-machine-learning.ai/blob/master/Gan's/vanillaGAN.ipynb\n","\n","### Recursos\n","\n","- https://github.com/Madhu009/Deep-math-machine-learning.ai/tree/master/Gan's\n","- https://machinelearningmastery.com/what-are-generative-adversarial-networks-gans/\n","- https://machinelearningmastery.com/resources-for-getting-started-with-generative-adversarial-networks/\n","- https://medium.com/ai-society/gans-from-scratch-1-a-deep-introduction-with-code-in-pytorch-and-tensorflow-cb03cdcdba0f\n","- http://ganocracy.csail.mit.edu/tutorial/tutorial.html\n","- https://poloclub.github.io/ganlab/\n","- https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29\n","- https://danieltakeshi.github.io/2017/03/05/understanding-generative-adversarial-networks/\n","- http://www.gatsby.ucl.ac.uk/~balaji/Understanding-GANs.pdf\n","- https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628\n","\n","### Trabajos interesantes\n","\n","- https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf\n","- https://github.com/NVIDIA/vid2vid"]}]}